{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3fb14ca1-a007-43b2-b111-45b6889b3bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from collections import Counter\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "fee015fc-4d3d-4d92-8f9a-ce69b1a7e936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para calcular la distancia Euclidiana\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "# Implementación manual de KNN para encontrar los k vecinos más cercanos\n",
    "def find_k_nearest_neighbors(X_train, x_test, k):\n",
    "    distances = []\n",
    "    for i, x_train in enumerate(X_train):\n",
    "        distance = euclidean_distance(x_train, x_test)\n",
    "        distances.append((distance, i))  # Guardamos la distancia y el índice\n",
    "    distances.sort(key=lambda x: x[0])  # Ordenar por distancia\n",
    "    return [idx for _, idx in distances[:k]]  # Retornar los índices de los k vecinos más cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "08dffd6e-75b1-41e2-a8a0-7c3cd300285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función de SMOTE\n",
    "def smote(X, y, k_sm=5):\n",
    "    counter = Counter(y)\n",
    "    max_count = max(counter.values())\n",
    "    minority_class = min(counter, key=counter.get)\n",
    "    majority_class = max(counter, key=counter.get)\n",
    "    \n",
    "    X_minority = X[y == minority_class]\n",
    "    num_samples_to_generate = max_count - counter[minority_class]\n",
    "    \n",
    "    synthetic_samples = []\n",
    "    \n",
    "    # Generar muestras sintéticas\n",
    "    for _ in range(num_samples_to_generate):\n",
    "        # Seleccionar una muestra aleatoria de la clase minoritaria\n",
    "        idx = np.random.randint(0, X_minority.shape[0])\n",
    "        point = X_minority[idx]\n",
    "        \n",
    "        # Encontrar los k vecinos más cercanos\n",
    "        neighbors_idx = find_k_nearest_neighbors(X_minority, point, k)\n",
    "        \n",
    "        # Seleccionar un vecino aleatorio\n",
    "        neighbor_idx = np.random.choice(neighbors_idx)\n",
    "        neighbor = X_minority[neighbor_idx]\n",
    "        \n",
    "        # Interpolación aleatoria entre la muestra y su vecino\n",
    "        alpha = np.random.rand()\n",
    "        synthetic_sample = point + alpha * (neighbor - point)\n",
    "        synthetic_samples.append(synthetic_sample)\n",
    "    \n",
    "    # Convertir las muestras sintéticas en un array numpy\n",
    "    X_synthetic = np.array(synthetic_samples)\n",
    "    y_synthetic = np.full(X_synthetic.shape[0], minority_class)\n",
    "    \n",
    "    # Combinar los datos originales con los sintéticos\n",
    "    X_sm = np.vstack([X, X_synthetic])\n",
    "    y_sm = np.hstack([y, y_synthetic])\n",
    "    \n",
    "    return X_sm, y_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2e199531-3c8b-4d29-86bc-82594d2f5a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_nn_classifier(X_train, y_train, X_test):\n",
    "    def euclidean_distance(x1, x2):\n",
    "        return sum((xi - yi) ** 2 for xi, yi in zip(x1, x2)) ** 0.5\n",
    "\n",
    "    y_pred = [] # Lista para almacenar las predicciones\n",
    "\n",
    "    # Predicción para cada muestra en el conjunto de prueba\n",
    "    for x_test in X_test:\n",
    "        # Inicializar la menor distancia como infinita y sin etiqueta\n",
    "        min_distance = float('inf')\n",
    "        closest_label = None\n",
    "\n",
    "        # Buscar el vecino más cercano\n",
    "        for i, x_train in enumerate(X_train):\n",
    "            distance = euclidean_distance(x_test, x_train)\n",
    "            if distance < min_distance:\n",
    "                min_distance = distance\n",
    "                closest_label = y_train[i]\n",
    "\n",
    "        y_pred.append(closest_label) # Guardar la predicción\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0cf892a6-81d1-4fe5-adf7-07e142a2bcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el clasificador KNN\n",
    "def knn_classifier(X_train, y_train, X_test, k):\n",
    "    def euclidean_distance(x1, x2):\n",
    "        return sum((xi - yi) ** 2 for xi, yi in zip(x1, x2)) ** 0.5\n",
    "\n",
    "    y_pred = []  # Lista para almacenar las predicciones\n",
    "\n",
    "    for x_test in X_test:\n",
    "        # Calcular la distancia de x_test a todos los puntos en X_train\n",
    "        distances = [(euclidean_distance(x_test, x_train), label) for x_train, label in zip(X_train, y_train)]\n",
    "        # Ordenar por distancia y seleccionar los k vecinos más cercanos\n",
    "        k_nearest_neighbors = sorted(distances, key=lambda x: x[0])[:k]\n",
    "        # Obtener las etiquetas de los k vecinos y elegir la más común\n",
    "        k_nearest_labels = [label for _, label in k_nearest_neighbors]\n",
    "        most_common_label = Counter(k_nearest_labels).most_common(1)[0][0]\n",
    "        y_pred.append(most_common_label)\n",
    "        \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "2f80ee73-8f19-426f-8231-651f1c8510cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hold_out_validation(data,k,r=0.3):\n",
    "    # Separar características y etiquetas\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "\n",
    "    # Verificar y limpiar etiquetas\n",
    "    valid_indices = ~pd.isnull(y)\n",
    "    X = X[valid_indices]\n",
    "    y = y[valid_indices]\n",
    "    y = y.astype(int)\n",
    "\n",
    "    # Determinar el tamaño de prueba y mezclar índices\n",
    "    n = len(X)\n",
    "    test_size = int(n * r)\n",
    "    indices = list(range(n))\n",
    "    random.shuffle(indices)\n",
    "\n",
    "    # Crear subconjuntos de entrenamiento y prueba\n",
    "    train_indices = np.array(indices[:n - test_size])\n",
    "    test_indices = np.array(indices[n - test_size:])\n",
    "    X_train, y_train = X[train_indices], y[train_indices]\n",
    "    X_test, y_test = X[test_indices], y[test_indices]\n",
    "\n",
    "    counter = Counter(y_train)\n",
    "    print('Before', counter)\n",
    "     # Predicción con el clasificador de knn y 1nn\n",
    "    y_pred_knn= knn_classifier(X_train, y_train, X_test, k=k)\n",
    "    y_pred_1nn = one_nn_classifier(X_train, y_train, X_test)\n",
    "\n",
    "    # Oversampling the train dataset using SMOTE\n",
    "    X_train_sm, y_train_sm = smote(X_train, y_train,k_sm=5)\n",
    "\n",
    "    counter = Counter(y_train_sm)\n",
    "    print('After SMOTE:', counter)\n",
    "\n",
    "    # Predicción con el clasificador de knn y 1nn\n",
    "    y_pred_knn_sm= knn_classifier(X_train_sm, y_train_sm, X_test, k=k)\n",
    "    y_pred_1nn_sm= one_nn_classifier(X_train_sm, y_train_sm, X_test)\n",
    "\n",
    "    #if y_train == y_train_sm:\n",
    "    #   print(\" Hold out SON IGUALES\")\n",
    "\n",
    "    return y_test, y_pred_knn, y_pred_1nn, y_pred_knn_sm, y_pred_1nn_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "4b0a6c4e-bace-4984-9088-372c9ce3fa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_validation(data,k,num_folds=10):\n",
    "    # Separar características y etiquetas\n",
    "    X = data.iloc[:, :-1].values\n",
    "    y = data.iloc[:, -1].values\n",
    "\n",
    "    # Dividir los datos en K partes (folds)\n",
    "    folds = np.array_split(data, num_folds)\n",
    "\n",
    "    # Listas para acumular los resultados \n",
    "    y_tests = []\n",
    "    y_preds_1nn = []\n",
    "    y_preds_knn = []\n",
    "    y_preds_1nn_sm = []\n",
    "    y_preds_knn_sm = []\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(num_folds):\n",
    "        # Crear conjuntos de prueba y entrenamiento\n",
    "        test_data = folds[i]\n",
    "        train_data = pd.concat([folds[j] for j in range(num_folds) if j != i])\n",
    "\n",
    "        X_train = train_data.iloc[:, :-1].values\n",
    "        y_train = train_data.iloc[:, -1].values\n",
    "        X_test = test_data.iloc[:, :-1].values\n",
    "        y_test = test_data.iloc[:, -1].values\n",
    "\n",
    "        counter = Counter(y_train)\n",
    "        print('Before', counter)\n",
    "        \n",
    "        # Predicciones usando el clasificador de knn y 1nn\n",
    "        y_pred_knn = knn_classifier(X_train, y_train, X_test,k=k)\n",
    "        y_pred_1nn = one_nn_classifier(X_train, y_train, X_test)\n",
    "\n",
    "        \n",
    "        # oversampling the train dataset using SMOTE\n",
    "        X_train_sm, y_train_sm = smote(X_train, y_train,k_sm=5)\n",
    "        \n",
    "        counter = Counter(y_train_sm)\n",
    "        print('After', counter)\n",
    "        \n",
    "        # Predicciones usando el clasificador de knn y 1nn\n",
    "        y_pred_knn_sm = knn_classifier(X_train_sm, y_train_sm, X_test,k=k)\n",
    "        y_pred_1nn_sm = one_nn_classifier(X_train_sm, y_train_sm, X_test)\n",
    "        \n",
    "        # Acumular los resultados de prueba y predicción\n",
    "        y_tests.extend(y_test)\n",
    "        y_preds_knn.extend(y_pred_knn)\n",
    "        y_preds_1nn.extend(y_pred_1nn)\n",
    "        y_preds_knn_sm.extend(y_pred_knn_sm)\n",
    "        y_preds_1nn_sm.extend(y_pred_1nn_sm)\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    return y_tests, y_preds_knn, y_preds_1nn, y_preds_knn_sm, y_preds_1nn_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "4ebdb6a7-43f5-4d04-806b-9fa83bb41d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_performance(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Matriz de Confusión:\\n\", conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "c0de4f4b-9f75-48ee-a9e3-bea2f5894abc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************************\n",
      "\n",
      "--- Validación en glass.csv ---\n",
      "Before Counter({2: 53, 1: 53, 7: 20, 5: 10, 3: 10, 6: 4})\n",
      "After SMOTE: Counter({2: 53, 1: 53, 6: 53, 7: 20, 5: 10, 3: 10})\n",
      "\n",
      "---- KNN ----\n",
      "Hold-Out (70/30 Estratificado):  (SIN SMOTE)\n",
      "Accuracy: 0.9365079365079365\n",
      "Matriz de Confusión:\n",
      " [[16  0  0  0  0  0]\n",
      " [ 0 23  0  0  0  0]\n",
      " [ 0  0  7  0  0  0]\n",
      " [ 0  0  0  3  0  0]\n",
      " [ 0  0  0  4  1  0]\n",
      " [ 0  0  0  0  0  9]]\n",
      "\n",
      "---- 1NN ----\n",
      "Hold-Out (70/30 Estratificado): (SIN SMOTE)\n",
      "Accuracy: 0.9682539682539683\n",
      "Matriz de Confusión:\n",
      " [[16  0  0  0  0  0]\n",
      " [ 0 23  0  0  0  0]\n",
      " [ 0  0  7  0  0  0]\n",
      " [ 0  0  0  3  0  0]\n",
      " [ 0  0  0  2  3  0]\n",
      " [ 0  0  0  0  0  9]]\n",
      "\n",
      "---- KNN ----\n",
      "Hold-Out (70/30 Estratificado):  (SMOTE)\n",
      "Accuracy: 0.9523809523809523\n",
      "Matriz de Confusión:\n",
      " [[16  0  0  0  0  0]\n",
      " [ 0 23  0  0  0  0]\n",
      " [ 0  0  7  0  0  0]\n",
      " [ 0  0  0  2  1  0]\n",
      " [ 0  0  0  0  5  0]\n",
      " [ 0  0  0  0  2  7]]\n",
      "\n",
      "---- 1NN ----\n",
      "Hold-Out (70/30 Estratificado): (SMOTE)\n",
      "Accuracy: 0.9682539682539683\n",
      "Matriz de Confusión:\n",
      " [[16  0  0  0  0  0]\n",
      " [ 0 23  0  0  0  0]\n",
      " [ 0  0  7  0  0  0]\n",
      " [ 0  0  0  3  0  0]\n",
      " [ 0  0  0  2  3  0]\n",
      " [ 0  0  0  0  0  9]]\n",
      "Before Counter({2: 76, 1: 47, 7: 29, 3: 17, 5: 13, 6: 9})\n",
      "After Counter({2: 76, 6: 76, 1: 47, 7: 29, 3: 17, 5: 13})\n",
      "Before Counter({2: 76, 1: 47, 7: 29, 3: 17, 5: 13, 6: 9})\n",
      "After Counter({2: 76, 6: 76, 1: 47, 7: 29, 3: 17, 5: 13})\n",
      "Before Counter({2: 76, 1: 47, 7: 29, 3: 17, 5: 13, 6: 9})\n",
      "After Counter({2: 76, 6: 76, 1: 47, 7: 29, 3: 17, 5: 13})\n",
      "Before Counter({1: 66, 2: 58, 7: 29, 3: 17, 5: 13, 6: 9})\n",
      "After Counter({1: 66, 6: 66, 2: 58, 7: 29, 3: 17, 5: 13})\n",
      "Before Counter({1: 69, 2: 55, 7: 29, 3: 17, 5: 13, 6: 9})\n",
      "After Counter({1: 69, 6: 69, 2: 55, 7: 29, 3: 17, 5: 13})\n",
      "Before Counter({1: 69, 2: 55, 7: 29, 3: 17, 5: 13, 6: 9})\n",
      "After Counter({1: 69, 6: 69, 2: 55, 7: 29, 3: 17, 5: 13})\n",
      "Before Counter({1: 69, 2: 60, 7: 29, 5: 13, 3: 12, 6: 9})\n",
      "After Counter({1: 69, 6: 69, 2: 60, 7: 29, 5: 13, 3: 12})\n",
      "Before Counter({2: 76, 1: 69, 7: 29, 6: 9, 3: 5, 5: 4})\n",
      "After Counter({2: 76, 5: 76, 1: 69, 7: 29, 6: 9, 3: 5})\n",
      "Before Counter({2: 76, 1: 69, 7: 21, 3: 17, 5: 9})\n",
      "After Counter({2: 76, 5: 76, 1: 69, 7: 21, 3: 17})\n",
      "Before Counter({2: 76, 1: 69, 3: 17, 5: 13, 6: 9, 7: 8})\n",
      "After Counter({2: 76, 7: 76, 1: 69, 3: 17, 5: 13, 6: 9})\n",
      "\n",
      "---- KNN ----\n",
      "10-Fold Cross-Validation Estratificado: (SIN SMOTE)\n",
      "Accuracy: 0.8262910798122066\n",
      "Matriz de Confusión:\n",
      " [[61  8  0  0  0  0]\n",
      " [ 7 63  6  0  0  0]\n",
      " [ 0  0 17  0  0  0]\n",
      " [ 0  0  0  6  7  0]\n",
      " [ 0  0  0  6  0  3]\n",
      " [ 0  0  0  0  0 29]]\n",
      "\n",
      "---- 1NN ----\n",
      "10-Fold Cross-Validation Estratificado: (SIN SMOTE)\n",
      "Accuracy: 0.8967136150234741\n",
      "Matriz de Confusión:\n",
      " [[69  0  0  0  0  0]\n",
      " [ 7 63  6  0  0  0]\n",
      " [ 0  0 17  0  0  0]\n",
      " [ 0  0  0 13  0  0]\n",
      " [ 0  0  0  6  0  3]\n",
      " [ 0  0  0  0  0 29]]\n",
      "\n",
      "---- KNN ----\n",
      "10-Fold Cross-Validation Estratificado: (SMOTE)\n",
      "Accuracy: 0.8450704225352113\n",
      "Matriz de Confusión:\n",
      " [[61  8  0  0  0  0]\n",
      " [ 7 63  6  0  0  0]\n",
      " [ 0  0 14  3  0  0]\n",
      " [ 0  0  0 13  0  0]\n",
      " [ 0  0  0  8  0  1]\n",
      " [ 0  0  0  0  0 29]]\n",
      "\n",
      "---- 1NN ----\n",
      "10-Fold Cross-Validation Estratificado: (SMOTE)\n",
      "Accuracy: 0.892018779342723\n",
      "Matriz de Confusión:\n",
      " [[69  0  0  0  0  0]\n",
      " [ 7 63  6  0  0  0]\n",
      " [ 0  0 16  1  0  0]\n",
      " [ 0  0  0 13  0  0]\n",
      " [ 0  0  0  6  0  3]\n",
      " [ 0  0  0  0  0 29]]\n"
     ]
    }
   ],
   "source": [
    "# Cargar y validar cada dataset\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "datasets = ['glass.csv']\n",
    "k = 10\n",
    "\n",
    "for dataset in datasets:\n",
    "    data = pd.read_csv(dataset)\n",
    "\n",
    "    print(f\"*******************************************************************************************\")\n",
    "    print(f\"\\n--- Validación en {dataset} ---\")\n",
    "    \n",
    "    # Hold-Out 70/30 Estratificado\n",
    "    y_test, y_preds_knn, y_preds_1nn, y_preds_knn_sm, y_preds_1nn_sm = hold_out_validation(data,k)\n",
    "    print(\"\\n---- KNN ----\\nHold-Out (70/30 Estratificado):  (SIN SMOTE)\")\n",
    "    evaluate_performance(y_test, y_preds_knn)\n",
    "    print(\"\\n---- 1NN ----\\nHold-Out (70/30 Estratificado): (SIN SMOTE)\")\n",
    "    evaluate_performance(y_test, y_preds_1nn)\n",
    "    print(\"\\n---- KNN ----\\nHold-Out (70/30 Estratificado):  (SMOTE)\")\n",
    "    evaluate_performance(y_test, y_preds_knn_sm)\n",
    "    print(\"\\n---- 1NN ----\\nHold-Out (70/30 Estratificado): (SMOTE)\")\n",
    "    evaluate_performance(y_test, y_preds_1nn_sm)\n",
    "    \n",
    "    # 10-Fold Cross-Validation Estratificado\n",
    "    y_test, y_preds_knn, y_preds_1nn, y_preds_knn_sm, y_preds_1nn_sm = k_fold_validation(data,k)\n",
    "    print(\"\\n---- KNN ----\\n10-Fold Cross-Validation Estratificado: (SIN SMOTE)\")\n",
    "    evaluate_performance(y_test, y_preds_knn)\n",
    "    print(\"\\n---- 1NN ----\\n10-Fold Cross-Validation Estratificado: (SIN SMOTE)\")\n",
    "    evaluate_performance(y_test, y_preds_1nn)\n",
    "    print(\"\\n---- KNN ----\\n10-Fold Cross-Validation Estratificado: (SMOTE)\")\n",
    "    evaluate_performance(y_test, y_preds_knn_sm)\n",
    "    print(\"\\n---- 1NN ----\\n10-Fold Cross-Validation Estratificado: (SMOTE)\")\n",
    "    evaluate_performance(y_test, y_preds_1nn_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36f6922-4fde-4382-b292-f367774f0dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e4c07b-9f45-4397-b6ef-fbf2facecf37",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
